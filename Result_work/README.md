# Учебный проект. Определение пола и возраста владельца HTTP cookie.

## Оглавление
[1. Описание проекта](#Описание-проекта)  
[2. Какой кейс решаем?](#Какой-кейс-решаем)  
[3. Краткая информация о данных](#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](#Этапы-работы-над-проектом)  
[5. Результат](#Результат)    
[6. Выводы](#Выводы) 


### Описание проекта 
Вопрос звучит так: сможем ли мы по таким цифровым следам пользователя (на каких сайтах с каких IP он сидел, сколько раз заходил, какое у него устройство) понять, кто этот пользователь? Мужчина или женщина? 

Действительно, в Digital-рекламе часто сегмент включает себя пол. Эта задача особенно актуальна для рекламных DSP-площадок, которые в OpenRTB запросах получают такие данные с частотой 200 000 запросов в секунду со всех сайтов, размещающих рекламу за деньги.


### Какой кейс решаем?    
Определение пола владельца HTTP cookie по истории активности пользователя в интернете на основе синтетических данных.

**Условия успешного выполнения проекта:**  
Для успешного выполнения проекта вам необходимо набрать 18 балл из 25 возможных.


### Краткая информация о данных
На входе мы получаем файл с данными о пользователях со следующими полями:
'region_name' – Регион<br/>
'city_name' – Населенный пункт<br/>
'cpe_manufacturer_name' – Производитель устройства<br/>
'cpe_model_name' – Модель устройства<br/>
'url_host' – Домен, с которого пришел рекламный запрос<br/>
'cpe_type_cd' – Тип устройства (смартфон или что-то другое)<br/>
'Cpe_model_os_type' – Операционка на устройстве<br/>
'price' – Оценка цены устройства<br/>
'date' – Дата<br/>
'part_of_day' – Время дня (утро, вечер, итд)<br/>
'request_cnt' – Число запросов одного пользователя за время дня (поле part_of_day)<br/>
'user_id' – ID пользователя<br/>
'age' – Возраст пользователя<br/>
'is_male' – Признак пользователя : мужчина (1-Да, 0-Нет) (целевой пр)<br/>

Данные находятся [по ссылке](https://drive.google.com/file/d/1NW867pOmm2wwnnOf2tkg5c041gi1I5Ol/view?usp=drive_link)
Так же в нашем распоряжении есть файл о регионах, который находится [здесь](https://drive.google.com/file/d/1JK_dq3PMkQns0c3nx7rQoavfBoCFd4EZ/view?usp=drive_link)
В процессе работы мы строим графики, которые я сохранила в двух форматах: [html](https://github.com/Eliseykina/sf_data_science/tree/main/project_1/charts/html) и [png](https://github.com/Eliseykina/sf_data_science/tree/main/project_1/charts/png). Графики формата png я вывела в jupiter notebook.


### Этапы работы над проектом 
1. Базовый анализ структуры данных.
2. Очистка данных
3. Разведывательный анализ.
4. Преобразование данных:
    В результате группировки данных по признаку 'user_id', были оставлены/добавлены следующие признаки:
    1) **region_name** - оставлен тот регион, где пользователь бывал чаще всего;
    2) **regions_cnt** - добавлено количество различных регионов, где регистрировался пользователь;
    3) **cpe_model_os_type**
    4) **cpe_manufacturer_name** - оставлены 4 самые популярные, остальные заменены на 'other'
    5) **cpe_model_name** - оставлены самые популярные (у которых > 100 пользователей), остальные заменены на 'other'
    6) **part_of_day__day** - суммарное количество запросов пользователя днём
    7) **part_of_day__evening** - суммарное количество запросов пользователя вечером
    8) **part_of_day__morning** - суммарное количество запросов пользователя утром
    9) **part_of_day__night** - суммарное количество запросов пользователя ночью
    Все категориальные признаки были преобразованы.
    Основываясь на посещаемых ресурсах, были созданы дополнительные векторные признаки.
5. Данные были разделены на тестовую и обучающую выборки, был проверен целевой признак на сбалансированность.
6. Данные были стандартизированы.
7. Были посторены и проанализированы следующие модели:
    - LogisticRegression
    - SVC
    - KNeighborsClassifier
    - DecisionTreeClassifier
    - RandomForestClassifier
8. На основании метрик была выбрана оптимальная модель и сделаны выводы.
5. Был составлен файл README.md.


### Выводы:  
Цель достигнута - база была преобразована, исследована и отредактирована. Выводы сделаны. На все промежуточные вопросы ответы были даны верные.

[к оглавлению](#Оглавление)


[Ссылка на проект](https://github.com/Eliseykina/sf_data_science/tree/main/project_1/)
